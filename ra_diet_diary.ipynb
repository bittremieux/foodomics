{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_types(gfop_metadata, simple_complex=None):\n",
    "    if simple_complex is not None:\n",
    "        gfop_metadata = gfop_metadata[\n",
    "            gfop_metadata['simple_complex'] == simple_complex]\n",
    "    col_sample_types = [f'sample_type_group{i}' for i in range(1, 7)]\n",
    "    return (gfop_metadata[['filename', *col_sample_types]]\n",
    "            .set_index('filename'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfop_metadata = pd.read_csv(\n",
    "    '../data/11442_foodomics_multiproject_metadata.txt', sep='\\t')\n",
    "# First row is empty.\n",
    "gfop_metadata = gfop_metadata.drop(index=0)\n",
    "# Remove trailing whitespace.\n",
    "gfop_metadata = gfop_metadata.apply(lambda col: col.str.strip()\n",
    "                                    if col.dtype == 'object' else col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_food_counts(gnps_network, sample_types, groups_included,\n",
    "                         filenames_included, level):\n",
    "    # Select GNPS job groups.\n",
    "    groups = {f'G{i}' for i in range(1, 7)}\n",
    "    groups_excluded = groups - set(groups_included)\n",
    "    df_selected = gnps_network[\n",
    "        (gnps_network[groups_included] > 0).all(axis=1) &\n",
    "        (gnps_network[groups_excluded] == 0).all(axis=1)].copy()\n",
    "    df_selected = df_selected[\n",
    "        df_selected['UniqueFileSources'].apply(lambda cluster_fn:\n",
    "            any(fn in cluster_fn for fn in filenames_included))]\n",
    "    filenames = (df_selected['UniqueFileSources'].str.split('|')\n",
    "                 .explode())\n",
    "    # Select food hierarchy levels.\n",
    "    sample_types = sample_types[f'sample_type_group{level}']\n",
    "    # Match the GNPS job results to the food sample types.\n",
    "    sample_types_selected = sample_types.reindex(filenames)\n",
    "    sample_types_selected = sample_types_selected.dropna()\n",
    "    # Discard samples that occur less frequent than water (blank).\n",
    "    water_count = (sample_types_selected == 'water').sum()\n",
    "    sample_counts = sample_types_selected.value_counts()\n",
    "    sample_counts_valid = sample_counts.index[sample_counts > water_count]\n",
    "    sample_types_selected = sample_types_selected[\n",
    "        sample_types_selected.isin(sample_counts_valid)]\n",
    "    # Get sample counts at the specified level.\n",
    "    return sample_types_selected.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_types = get_sample_types(gfop_metadata)\n",
    "sample_types_simple = get_sample_types(gfop_metadata, 'simple')\n",
    "sample_types_complex = get_sample_types(gfop_metadata, 'complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('..', 'data', '12_26_RA fecal - plasma - food - '\n",
    "                        'FoodOmics 3500 FDR 0.01 tol 0.01 min 2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(os.path.join(data_dir, 'ra_qiime2_metadata.tsv'),\n",
    "                       sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnps_network = pd.read_csv(\n",
    "    os.path.join(data_dir, 'METABOLOMICS-SNETS-V2-0794151f-'\n",
    "                 'view_all_clusters_withID_beta-main.tsv'),\n",
    "    sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate number of matches to food categories per file.\n",
    "level = 4\n",
    "food_counts, filenames = [], []\n",
    "for sample_type, groups in [#('stool', ['G1', 'G4']),\n",
    "                            ('plasma', ['G2', 'G4'])]:\n",
    "    metadata_group = metadata[\n",
    "        metadata['ATTRIBUTE_SampleTypeSub1'] == sample_type]\n",
    "    for filename in metadata_group['filename']:\n",
    "        file_food_counts = get_file_food_counts(\n",
    "            gnps_network, sample_types, groups, [filename], level)\n",
    "        if len(file_food_counts) > 0:\n",
    "            food_counts.append(file_food_counts)\n",
    "            filenames.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts = (pd.concat(food_counts, axis=1, sort=True)\n",
    "               .fillna(0).astype(int).T)\n",
    "food_counts.index = pd.Index(filenames, name='filename')\n",
    "food_counts = food_counts.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map GFOP foods to foods specified in the diet diary.\n",
    "food_map = pd.read_csv(os.path.join(data_dir, 'ra_diary_gfop_map.csv'))\n",
    "# Split multiply matching foods.\n",
    "food_map['STG5'] = food_map['STG5'].str.split(';')\n",
    "food_map = food_map.explode('STG5')\n",
    "# Add level 4 foods from their level 5 successors.\n",
    "map_level45 = (sample_types[['sample_type_group4', 'sample_type_group5']]\n",
    "               .reset_index(drop=True).drop_duplicates())\n",
    "map_level45 = (map_level45[map_level45['sample_type_group5']\n",
    "                           .isin(food_map['STG5'])]\n",
    "               .set_index('sample_type_group5').squeeze().to_dict())\n",
    "# Force map complex as it can map to a lot of different things.\n",
    "map_level45['complex'] = 'complex'\n",
    "# Missing entries.\n",
    "map_level45['not represented'] = 'not represented'\n",
    "food_map['STG4'] = food_map['STG5'].map(map_level45)\n",
    "food_map = food_map.sort_values(['STG4', 'STG5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-reported diet diary.\n",
    "diary = (pd.read_csv(os.path.join(data_dir, 'ra_diet_diary.csv'),\n",
    "                     index_col='Diary_category')\n",
    "         .dropna('columns', 'all').replace({'yes': True, 'no': False}).T\n",
    "         .rename_axis(columns=None))\n",
    "diary['study_id'] = diary.index.str[1:5]\n",
    "diary['time'] = diary.index.str[6:].astype(int)\n",
    "diary = diary.set_index(['study_id', 'time'])\n",
    "column_rename = (food_map[[f'STG{level}', 'Diary_category']]\n",
    "                 .set_index('Diary_category').squeeze().to_dict())\n",
    "# Combine diary entries that match to multiple foods\n",
    "# by aggregating their absence/presence values.\n",
    "diary = (diary.rename(columns=column_rename).drop(columns='not represented')\n",
    "         .sort_index('columns').groupby(axis='columns', level=0).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert between patient identifiers and run names.\n",
    "patient_map = pd.read_csv(os.path.join(data_dir, 'ra_patient_map.csv'))\n",
    "patient_map['study_id'] = patient_map['study_id'].str[:4]\n",
    "patient_map['patient'] = patient_map['patient'].str[:4]\n",
    "patient_map = patient_map.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts.index = food_counts.index.str[1:-6]\n",
    "food_counts['time'] = 0\n",
    "food_counts.loc[food_counts.index.str.endswith('T1'), 'time'] = -14\n",
    "food_counts.loc[food_counts.index.str.endswith('T3'), 'time'] = 14\n",
    "food_counts.index = (food_counts.index.str[:-3].map(\n",
    "    patient_map.set_index('patient').squeeze().to_dict()).rename('study_id'))\n",
    "food_counts = food_counts.set_index('time', append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_foods = (food_counts.columns & diary.columns).drop('complex')\n",
    "food_counts = food_counts[shared_foods]\n",
    "diary = diary[shared_foods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = []\n",
    "study_ids = (food_counts.index.get_level_values('study_id').unique() &\n",
    "             diary.index.get_level_values('study_id').unique())\n",
    "for study_id in study_ids:\n",
    "    food_counts_study = food_counts[\n",
    "        food_counts.index.get_level_values('study_id') == study_id]\n",
    "    diary_study = diary[\n",
    "        diary.index.get_level_values('study_id') == study_id]\n",
    "    for food_counts_time, food_counts_time_study in food_counts_study.iterrows():\n",
    "        for diary_time, diary_time_study in diary_study.iterrows():\n",
    "            statistic, _ = stats.kendalltau(food_counts_time_study, diary_time_study)\n",
    "            statistics.append((*food_counts_time, diary_time[1], statistic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = pd.DataFrame(statistics, columns=[\n",
    "    'study_id', 'MS timepoint', 'Diary timepoint', 'Kendall\\'s tau'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x='Diary timepoint', y='Kendall\\'s tau', data=statistics,\n",
    "            col='MS timepoint', kind='box', height=6, aspect=1.5)\n",
    "\n",
    "plt.savefig('ra_diet_diary.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 14\n",
    "height = width / 1.618\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "food_counts_norm = food_counts.divide(food_counts.sum(axis=1), axis=0)\n",
    "order = food_counts_norm.sum(axis=0).sort_values(ascending=False).index\n",
    "with sns.color_palette('tab20'):\n",
    "    food_counts_norm[order].plot.bar(ax=ax, stacked=True)\n",
    "\n",
    "ax.set_xticklabels([f'P{study_id}T{time}'\n",
    "                    for study_id, time in food_counts.index], rotation=90)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mticker.PercentFormatter(1))\n",
    "\n",
    "ax.set_xlabel('Patient at timepoint')\n",
    "ax.set_ylabel('Relative food count')\n",
    "\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1.05, 0.5), ncol=2,\n",
    "          frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('ra_individual_food_count.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts_norm_intervention = food_counts_norm.xs(14, level='time')\n",
    "food_counts_norm_intervention = food_counts_norm_intervention.loc[\n",
    "    :, (food_counts_norm_intervention != 0).any(axis=0)]\n",
    "sns.clustermap(food_counts_norm_intervention.corr(), figsize=(10, 10),\n",
    "               vmin=-1, vmax=1)\n",
    "\n",
    "plt.savefig('ra_food_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
