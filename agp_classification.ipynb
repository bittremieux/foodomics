{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import average_precision_score, \\\n",
    "    balanced_accuracy_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, \\\n",
    "    StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='sans-serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts = pd.read_csv(\n",
    "    '../data/AGP/'\n",
    "    'agp_g1g4_plant_file_food_count.csv').set_index('filename')\n",
    "sample_metadata = pd.read_csv(\n",
    "    '../data/AGP/'\n",
    "    'modified_AGP_metadata_survey_1_md_final_mergeAGPplantset_JMG.txt',\n",
    "    sep='\\t', index_col='filename',\n",
    "    usecols=['filename', 'analysis_high_low_plant']).squeeze()\n",
    "\n",
    "sample_metadata = (sample_metadata[~sample_metadata.index.duplicated()]\n",
    "                   .reindex(food_counts.index))\n",
    "food_counts = food_counts.reindex(sample_metadata.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = food_counts.div(food_counts.sum(axis=1), axis=0)\n",
    "clss = np.asarray(sample_metadata == 'high', np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeatedly evaluate the model to estimate its performance.\n",
    "n_splits = 10\n",
    "test_size = 0.2\n",
    "accuracies_train = np.empty(n_splits, np.float32)\n",
    "accuracies_test = np.empty(n_splits, np.float32)\n",
    "average_precisions_train = np.empty(n_splits, np.float32)\n",
    "average_precisions_test = np.empty(n_splits, np.float32)\n",
    "roc_aucs_train = np.empty(n_splits, np.float32)\n",
    "roc_aucs_test = np.empty(n_splits, np.float32)\n",
    "interval = np.linspace(0, 1, 101, dtype=np.float32)\n",
    "tprs_train = np.empty((n_splits, 101), np.float32)\n",
    "tprs_test = np.empty((n_splits, 101), np.float32)\n",
    "precisions_train = np.empty((n_splits, 101), np.float32)\n",
    "precisions_test = np.empty((n_splits, 101), np.float32)\n",
    "feature_importances = np.zeros((n_splits, len(features.columns.values)),\n",
    "                               np.float32)\n",
    "best_params = []\n",
    "for i, (train_index, test_index) in enumerate(\n",
    "        StratifiedShuffleSplit(n_splits, test_size, random_state=42).split(\n",
    "            features.values, clss)):\n",
    "    features_train, features_test = (features.values[train_index],\n",
    "                                     features.values[test_index])\n",
    "    clss_train, clss_test = clss[train_index], clss[test_index]\n",
    "    \n",
    "    n_trees = 100\n",
    "    classifier = GridSearchCV(\n",
    "        Pipeline([('feature_selection', SelectKBest()),\n",
    "                  ('classify', RandomForestClassifier(\n",
    "                      n_trees, random_state=42,\n",
    "                      class_weight='balanced_subsample'))]),\n",
    "        param_grid={\n",
    "            'feature_selection__k': np.arange(5, 51, 5),\n",
    "            'classify__max_depth': np.arange(3, 8, 1),\n",
    "            'classify__min_samples_leaf': np.arange(1, 4, 1)},\n",
    "        n_jobs=-1,\n",
    "        cv=StratifiedShuffleSplit(n_splits, test_size, random_state=42))\n",
    "    \n",
    "    classifier.fit(features_train, clss_train)\n",
    "    pred_train = classifier.predict_proba(features_train)[:, 1]\n",
    "    pred_test = classifier.predict_proba(features_test)[:, 1]\n",
    "    \n",
    "    # Compute evaluation metrics on the train and test data.\n",
    "    accuracies_train[i] = balanced_accuracy_score(\n",
    "            clss_train, np.asarray(pred_train > 0.5, np.int))\n",
    "    accuracies_test[i] = balanced_accuracy_score(\n",
    "            clss_test, np.asarray(pred_test > 0.5, np.int))\n",
    "    average_precisions_train[i] = average_precision_score(\n",
    "        clss_train, pred_train)\n",
    "    average_precisions_test[i] = average_precision_score(\n",
    "        clss_test, pred_test)\n",
    "    roc_aucs_train[i] = roc_auc_score(clss_train, pred_train)\n",
    "    roc_aucs_test[i] = roc_auc_score(clss_test, pred_test)\n",
    "    fpr_train, tpr_train, _ = roc_curve(clss_train, pred_train)\n",
    "    tprs_train[i] = np.interp(interval, fpr_train, tpr_train)\n",
    "    fpr_test, tpr_test, _ = roc_curve(clss_test, pred_test)\n",
    "    tprs_test[i] = np.interp(interval, fpr_test, tpr_test)\n",
    "    precision_train, recall_train, _ = precision_recall_curve(\n",
    "        clss_train, pred_train)\n",
    "    precisions_train[i] = np.interp(\n",
    "        interval, recall_train[::-1], precision_train[::-1])\n",
    "    precision_test, recall_test, _ = precision_recall_curve(\n",
    "        clss_test, pred_test)\n",
    "    precisions_test[i] = np.interp(\n",
    "        interval, recall_test[::-1], precision_test[::-1])\n",
    "    selected_features_mask = (classifier.best_estimator_\n",
    "                              .named_steps['feature_selection']\n",
    "                              .get_support())\n",
    "    feat_imp = permutation_importance(\n",
    "        classifier.best_estimator_.named_steps['classify'],\n",
    "        features.values[:, selected_features_mask],\n",
    "        clss, n_jobs=-1, random_state=42)\n",
    "    feature_importances[i, selected_features_mask] += \\\n",
    "        feat_imp.importances_mean\n",
    "    # Save optimal hyperparameters.\n",
    "    best_params.append((\n",
    "        classifier.best_estimator_.named_steps['feature_selection'].k,\n",
    "        classifier.best_estimator_.named_steps['classify'].max_depth,\n",
    "        classifier.best_estimator_.named_steps['classify'].min_samples_leaf))\n",
    "    \n",
    "\n",
    "stats = {'accuracy_train': np.mean(accuracies_train),\n",
    "         'accuracy_std_train': np.std(accuracies_train),\n",
    "         'average_precision_train': np.mean(average_precisions_train),\n",
    "         'average_precision_std_train': np.std(average_precisions_train),\n",
    "         'roc_auc_train': np.mean(roc_aucs_train),\n",
    "         'roc_auc_std_train': np.std(roc_aucs_train),\n",
    "         'tpr_mean_train': np.mean(tprs_train, axis=0),\n",
    "         'tpr_std_train': np.std(tprs_train, axis=0),\n",
    "         'precision_mean_train': np.mean(precisions_train, axis=0),\n",
    "         'precision_std_train': np.std(precisions_train, axis=0),\n",
    "        \n",
    "         'accuracy_test': np.mean(accuracies_test),\n",
    "         'accuracy_std_test': np.std(accuracies_test),\n",
    "         'average_precision_test': np.mean(average_precisions_test),\n",
    "         'average_precision_std_test': np.std(average_precisions_test),\n",
    "         'roc_auc_test': np.mean(roc_aucs_test),\n",
    "         'roc_auc_std_test': np.std(roc_aucs_test),\n",
    "         'tpr_mean_test': np.mean(tprs_test, axis=0),\n",
    "         'tpr_std_test': np.std(tprs_test, axis=0),\n",
    "         'precision_mean_test': np.mean(precisions_test, axis=0),\n",
    "         'precision_std_test': np.std(precisions_test, axis=0),\n",
    "         \n",
    "         'feature_importances': np.mean(feature_importances, axis=0),\n",
    "         'feature_importances_std': np.std(feature_importances, axis=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax = axes[0]\n",
    "interval = np.linspace(0, 1, 101)\n",
    "tpr_train = stats['tpr_mean_train']\n",
    "tpr_train[0], tpr_train[-1] = 0, 1\n",
    "ax.plot(interval, tpr_train,\n",
    "        label=f'AUC (train) = {stats[\"roc_auc_train\"]:.3f} '\n",
    "              f'± {stats[\"roc_auc_std_train\"]:.3f}')\n",
    "ax.fill_between(interval, tpr_train - stats['tpr_std_train'],\n",
    "                tpr_train + stats['tpr_std_train'], alpha=0.2)\n",
    "tpr_test = stats['tpr_mean_test']\n",
    "tpr_test[0], tpr_test[-1] = 0, 1\n",
    "ax.plot(interval, tpr_test,\n",
    "        label=f'AUC (test) = {stats[\"roc_auc_test\"]:.3f} '\n",
    "              f'± {stats[\"roc_auc_std_test\"]:.3f}')\n",
    "ax.fill_between(interval, tpr_test - stats['tpr_std_test'],\n",
    "                tpr_test + stats['tpr_std_test'], alpha=0.2)\n",
    "        \n",
    "ax.plot([0, 1], [0, 1], c='black', ls='--')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "        \n",
    "ax = axes[1]\n",
    "precision_train = stats['precision_mean_train']\n",
    "ax.plot(interval, precision_train,\n",
    "        label=f'Avg precision (train) = '\n",
    "              f'{stats[\"average_precision_train\"]:.3f} ± '\n",
    "              f'{stats[\"average_precision_std_train\"]:.3f}')\n",
    "ax.fill_between(interval, precision_train - stats['precision_std_train'],\n",
    "                precision_train + stats['precision_std_train'], alpha=0.2)\n",
    "precision_test = stats['precision_mean_test']\n",
    "ax.plot(interval, precision_test,\n",
    "        label=f'Avg precision (test) = '\n",
    "              f'{stats[\"average_precision_test\"]:.3f} ± '\n",
    "              f'{stats[\"average_precision_std_test\"]:.3f}')\n",
    "ax.fill_between(interval, precision_test - stats['precision_std_test'],\n",
    "                precision_test + stats['precision_std_test'], alpha=0.2)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('agp_classification.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = scipy.stats.mode(best_params)[0][0]\n",
    "print(f'Optimal number of features (mode): {final_params[0]}')\n",
    "print(f'Optimal number of maximum depth (mode): {final_params[1]}')\n",
    "print(f'Optimal number of minimum leaf samples (mode): {final_params[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 6))\n",
    "\n",
    "feature_importances = pd.DataFrame(\n",
    "    {'feature_importance': stats['feature_importances'],\n",
    "     'std': stats['feature_importances_std']},\n",
    "    index=features.columns.values)\n",
    "feature_importances = feature_importances.sort_values(\n",
    "    'feature_importance', ascending=False).head(20)\n",
    "feature_importances['feature_importance'].plot.bar(\n",
    "    yerr=feature_importances['std'], legend=False, ax=ax)\n",
    "\n",
    "ax.set_ylim(0, ax.get_ylim()[1])\n",
    "\n",
    "ax.set_xlabel('Feature')\n",
    "ax.set_ylabel('Feature importance')\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('agp_classification_feature_importances.png', dpi=300,\n",
    "            bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
