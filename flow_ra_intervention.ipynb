{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import floweaver\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFOP sample type metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sample_types(gfop_metadata, simple_complex=None):\n",
    "    if simple_complex is not None:\n",
    "        gfop_metadata = gfop_metadata[\n",
    "            gfop_metadata['simple_complex'] == simple_complex]\n",
    "    col_sample_types = [f'sample_type_group{i}' for i in range(1, 7)]\n",
    "    return (gfop_metadata[['filename', *col_sample_types]]\n",
    "            .set_index('filename'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gfop_metadata = pd.read_csv(\n",
    "    '../data/11442_foodomics_multiproject_metadata.txt', sep='\\t')\n",
    "# First row is empty.\n",
    "gfop_metadata = gfop_metadata.drop(index=0)\n",
    "# Remove trailing whitespace.\n",
    "gfop_metadata = gfop_metadata.apply(lambda col: col.str.strip()\n",
    "                                    if col.dtype == 'object' else col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Food type at different metadata levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def _get_flows(gnps_network, sample_types, groups_included,\n",
    "               filenames_included, max_hierarchy_level):\n",
    "    # Select GNPS job groups.\n",
    "    groups = {f'G{i}' for i in range(1, 7)}\n",
    "    groups_excluded = groups - set(groups_included)\n",
    "    df_selected = gnps_network[\n",
    "        (gnps_network[groups_included] > 0).all(axis=1) &\n",
    "        (gnps_network[groups_excluded] == 0).all(axis=1)].copy()\n",
    "    df_selected = df_selected[\n",
    "        df_selected['UniqueFileSources'].apply(lambda cluster_fn:\n",
    "            any(fn in cluster_fn for fn in filenames_included))]\n",
    "    filenames = (df_selected['UniqueFileSources'].str.split('|')\n",
    "                 .explode())\n",
    "    # Select food hierarchy levels.\n",
    "    sample_types = sample_types[[\n",
    "        f'sample_type_group{i}' for i in range(1, max_hierarchy_level + 1)]]\n",
    "    # Match the GNPS job results to the food sample types.\n",
    "    sample_types_selected = sample_types.reindex(filenames)\n",
    "    sample_types_selected = sample_types_selected.dropna()\n",
    "    # Discard samples that occur less frequent than water (blank).\n",
    "    water_count = ((sample_types_selected['sample_type_group1'] == 'water')\n",
    "                   .sum())\n",
    "    sample_counts = sample_types_selected[\n",
    "        f'sample_type_group{max_hierarchy_level}'].value_counts()\n",
    "    sample_counts_valid = sample_counts.index[sample_counts > water_count]\n",
    "    sample_types_selected = sample_types_selected[sample_types_selected[\n",
    "        f'sample_type_group{max_hierarchy_level}'].isin(sample_counts_valid)]\n",
    "    # Get the flows between consecutive food hierarchy levels.\n",
    "    flows, processes = [], []\n",
    "    for i in range(1, max_hierarchy_level):\n",
    "        g1, g2 = f'sample_type_group{i}', f'sample_type_group{i + 1}'\n",
    "        flow = (sample_types_selected.groupby([g1, g2]).size()\n",
    "                .reset_index().rename(columns={g1: 'source', g2: 'target',\n",
    "                                               0: 'value'}))\n",
    "        flow['source'] = flow['source'] + f'_{i}'\n",
    "        flow['target'] = flow['target'] + f'_{i + 1}'\n",
    "        flow['type'] = flow['target']\n",
    "        flows.append(flow)\n",
    "        process = pd.concat([flow['source'], flow['target']],\n",
    "                            ignore_index=True).to_frame()\n",
    "        process['level'] = [*np.repeat(i, len(flow['source'])),\n",
    "                            *np.repeat(i + 1, len(flow['target']))]\n",
    "        processes.append(process)\n",
    "    return (pd.concat(flows, ignore_index=True),\n",
    "            pd.concat(processes, ignore_index=True).drop_duplicates()\n",
    "            .rename(columns={0: 'id'}).set_index('id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_flows(gnps_network, sample_types, groups_included,\n",
    "               filenames_included, sample_type_hierarchy,\n",
    "               max_hierarchy_level=4, filename=None):\n",
    "    flows, processes = _get_flows(\n",
    "        gnps_network, sample_types, groups_included, filenames_included,\n",
    "        max_hierarchy_level)\n",
    "    dataset = floweaver.Dataset(flows, dim_process=processes)\n",
    "    \n",
    "    food_counts = (flows[flows['target'].str.endswith(\n",
    "                       f'_{max_hierarchy_level}')][['target', 'value']]\n",
    "                   .rename(columns={'target': 'food', 'value': 'count'})\n",
    "                   .set_index('food').squeeze())\n",
    "\n",
    "    labels = (sample_type_hierarchy\n",
    "              .reindex(set(flows['source']) | set(flows['target']))\n",
    "              .sort_values('order_num').index)\n",
    "    nodes, ordering, bundles = {}, [], []\n",
    "    for level in processes['level'].unique():\n",
    "        nodes[f'level {level}'] = floweaver.ProcessGroup(f'level == {level}')\n",
    "        nodes[f'level {level}'].partition = floweaver.Partition.Simple(\n",
    "            'process', labels[labels.str.endswith(f'_{level}')][::-1])\n",
    "\n",
    "        ordering.append([f'level {level}'])\n",
    "\n",
    "        if level + 1 in processes['level'].unique():\n",
    "            bundles.append(floweaver.Bundle(f'level {level}',\n",
    "                                            f'level {level + 1}'))\n",
    "\n",
    "    sdd = floweaver.SankeyDefinition(\n",
    "        nodes, bundles, ordering, flow_partition=dataset.partition('type'))\n",
    "    palette = sample_type_hierarchy['color_code'].dropna().to_dict()\n",
    "    return floweaver.weave(sdd, dataset, palette=palette), food_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_types_simple = get_sample_types(gfop_metadata, 'simple')\n",
    "sample_types_complex = get_sample_types(gfop_metadata, 'complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_type_hierarchy = (\n",
    "    pd.read_csv('../data/sample_type_hierarchy.csv')\n",
    "    .set_index('descriptor').sort_values('order_num'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ra_metadata = pd.read_csv(\n",
    "    '../data/'\n",
    "    '12_26_RA fecal - plasma - food - FoodOmics 3500 FDR 0.01 tol 0.01 min 2/'\n",
    "    'ra_qiime2_metadata.tsv', sep='\\t')\n",
    "filenames_pre = (ra_metadata[\n",
    "    ra_metadata['ATTRIBUTE_Intervention'] == '1_pre']['filename'].unique())\n",
    "filenames_post = (ra_metadata[\n",
    "    ra_metadata['ATTRIBUTE_Intervention'] == '2_post']['filename'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnps_network = pd.read_csv(\n",
    "    '../data/12_26_RA fecal - plasma - food - FoodOmics 3500 FDR 0.01 tol 0.01 min 2/'\n",
    "    'METABOLOMICS-SNETS-V2-0794151f-view_all_clusters_withID_beta-main.tsv',\n",
    "    sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'folder12'\n",
    "simple_complex = 'simple'\n",
    "groups = '1', '3', '4'\n",
    "max_level = 4\n",
    "\n",
    "if simple_complex == 'simple':\n",
    "    sample_types = sample_types_simple\n",
    "elif simple_complex == 'complex':\n",
    "    sample_types = sample_types_complex\n",
    "else:\n",
    "    raise ValueError('Unknown sample type')\n",
    "\n",
    "width, height = 1200, 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flows pre diet intervention.\n",
    "sankey_data, food_counts_pre = plot_flows(\n",
    "    gnps_network, sample_types, [f'G{g}' for g in groups], filenames_pre,\n",
    "    sample_type_hierarchy, max_level)\n",
    "(sankey_data.to_widget(width=width, height=height, margins={\n",
    "    'left': 150, 'right': 150, 'top': -50, 'bottom': -50})\n",
    " .auto_save_png(f'flow_{dataset}_g{\"\".join(groups)}_level{max_level}_'\n",
    "                f'{simple_complex}_pre.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Flows post diet intervention.\n",
    "sankey_data, food_counts_post = plot_flows(\n",
    "    gnps_network, sample_types, [f'G{g}' for g in groups], filenames_post,\n",
    "    sample_type_hierarchy, max_level)\n",
    "(sankey_data.to_widget(width=width, height=height, margins={\n",
    "    'left': 150, 'right': 150, 'top': -50, 'bottom': -50})\n",
    " .auto_save_png(f'flow_{dataset}_g{\"\".join(groups)}_level{max_level}_'\n",
    "                f'{simple_complex}_post.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts_diff = (pd.merge(food_counts_pre, food_counts_post, 'outer',\n",
    "                             left_index=True, right_index=True)\n",
    "                    .fillna(0)\n",
    "                    .rename(columns={'count_x': 'count_pre',\n",
    "                                     'count_y': 'count_post'}))\n",
    "food_counts_diff['count_pre'] = food_counts_diff['count_pre'].astype(int)\n",
    "food_counts_diff['count_post'] = food_counts_diff['count_post'].astype(int)\n",
    "food_counts_diff['ratio'] = (food_counts_diff['count_post']\n",
    "                             / food_counts_diff['count_pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(food_counts_diff.sort_values('ratio')\n",
    " .to_csv(f'ra_intervention_g{\"\".join(groups)}_level{max_level}_'\n",
    "         f'{simple_complex}.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
