{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GFOP sample type metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_sample_types(gfop_metadata, simple_complex=None):\n",
    "    if simple_complex is not None:\n",
    "        gfop_metadata = gfop_metadata[\n",
    "            gfop_metadata['simple_complex'] == simple_complex]\n",
    "    col_sample_types = [f'sample_type_group{i}' for i in range(1, 7)]\n",
    "    return (gfop_metadata[['filename', *col_sample_types]]\n",
    "            .set_index('filename'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gfop_metadata = pd.read_csv(\n",
    "    '../data/11442_foodomics_multiproject_metadata.txt', sep='\\t')\n",
    "# First row is empty.\n",
    "gfop_metadata = gfop_metadata.drop(index=0)\n",
    "# Remove trailing whitespace.\n",
    "gfop_metadata = gfop_metadata.apply(lambda col: col.str.strip()\n",
    "                                    if col.dtype == 'object' else col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate coffee/tea consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_food_counts(gnps_network, sample_types, groups_included,\n",
    "                         filenames_included, level):\n",
    "    # Select GNPS job groups.\n",
    "    groups = {f'G{i}' for i in range(1, 7)}\n",
    "    groups_excluded = groups - set(groups_included)\n",
    "    df_selected = gnps_network[\n",
    "        (gnps_network[groups_included] > 0).all(axis=1) &\n",
    "        (gnps_network[groups_excluded] == 0).all(axis=1)].copy()\n",
    "    df_selected = df_selected[\n",
    "        df_selected['UniqueFileSources'].apply(lambda cluster_fn:\n",
    "            any(fn in cluster_fn for fn in filenames_included))]\n",
    "    filenames = df_selected['UniqueFileSources'].str.split('|').explode()\n",
    "    # Select food hierarchy levels.\n",
    "    sample_types = sample_types[f'sample_type_group{level}']\n",
    "    # Match the GNPS job results to the food sample types.\n",
    "    sample_types_selected = sample_types.reindex(filenames)\n",
    "    sample_types_selected = sample_types_selected.dropna()\n",
    "    # Discard samples that occur less frequent than water (blank).\n",
    "    water_count = (sample_types_selected == 'water').sum()\n",
    "    sample_counts = sample_types_selected.value_counts()\n",
    "    sample_counts_valid = sample_counts.index[sample_counts > water_count]\n",
    "    sample_types_selected = sample_types_selected[\n",
    "        sample_types_selected.isin(sample_counts_valid)]\n",
    "    # Get sample counts at the specified level.\n",
    "    counts = sample_types_selected.value_counts()\n",
    "    counts = counts.append(pd.Series(\n",
    "        {'caffeine': (df_selected['LibraryID'].str.lower()\n",
    "                      .str.contains('caffeine').sum()),\n",
    "         'theophylline': (df_selected['LibraryID'].str.lower()\n",
    "                          .str.contains('theophylline').sum())}))\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cooccurring_foods(gnps_network, sample_types, groups_included,\n",
    "                          cooccurring_foods, level):\n",
    "    # Select GNPS job groups.\n",
    "    groups_included = ['G2', 'G4']\n",
    "    groups = {f'G{i}' for i in range(1, 7)}\n",
    "    groups_excluded = groups - set(groups_included)\n",
    "    df_selected = gnps_network[\n",
    "        (gnps_network[groups_included] > 0).all(axis=1) &\n",
    "        (gnps_network[groups_excluded] == 0).all(axis=1)].copy()\n",
    "    # Select food hierarchy levels.\n",
    "    sample_types = sample_types[f'sample_type_group{level}']\n",
    "    # Find food types for filenames that co-occur with the specified foods.\n",
    "    filenames_cooccurring = sample_types.reindex(\n",
    "        df_selected['UniqueFileSources'].str.split('|').explode().unique())\n",
    "    filenames_cooccurring = filenames_cooccurring[\n",
    "        filenames_cooccurring.isin(cooccurring_foods)].index\n",
    "    filenames_cooccurring = df_selected[\n",
    "        df_selected['UniqueFileSources'].str.contains(\n",
    "            '|'.join(filenames_cooccurring))]['UniqueFileSources']\n",
    "    return sample_types.reindex(filenames_cooccurring.str.split('|')\n",
    "                                .explode().unique()).dropna().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_types_simple = get_sample_types(gfop_metadata, 'simple')\n",
    "sample_types_complex = get_sample_types(gfop_metadata, 'complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_type_hierarchy = (\n",
    "    pd.read_csv('../data/sample_type_hierarchy.csv')\n",
    "    .set_index('descriptor').sort_values('order_num'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gnps_network = pd.read_csv(\n",
    "    '../data/3_22_ONR Fecal match - ONR Plasma match - ONR Food - FoodOmics 3500 (no ONR) FDR 0.01/'\n",
    "    'METABOLOMICS-SNETS-V2-9a90bd12-view_all_clusters_withID_beta-main.tsv',\n",
    "    sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 5\n",
    "groups = ['G2', 'G4']\n",
    "sample = 'plasma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\n",
    "    f'../data/3_22_ONR Fecal match - ONR Plasma match - ONR Food - FoodOmics 3500 (no ONR) FDR 0.01/'\n",
    "    f'onr_{sample}_metadata.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts, index = [], []\n",
    "for timepoint, filenames in (metadata.groupby('Study_DayAsReported')\n",
    "                             ['filename'].agg(list).items()):\n",
    "    file_food_counts = get_file_food_counts(\n",
    "        gnps_network, sample_types_simple, groups, filenames, level)\n",
    "    if len(file_food_counts) > 0:\n",
    "        food_counts.append(file_food_counts)\n",
    "        index.append(timepoint)\n",
    "\n",
    "food_counts = (pd.concat(food_counts, axis=1, sort=True)\n",
    "               .fillna(0).astype(int).T)\n",
    "food_counts.index = pd.Index(index, name='day')\n",
    "food_counts = food_counts[['caffeine', 'theophylline'] +\n",
    "                          [col for col in food_counts.columns\n",
    "                           if col not in ['caffeine', 'theophylline']]]\n",
    "food_counts.to_csv(f'onr_{sample}_timepoints.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts, index = [], []\n",
    "for timepoint, filenames in (metadata.groupby('Study_DayAsReported')\n",
    "                             ['filename'].agg(list).items()):\n",
    "    for filename in filenames:\n",
    "        file_food_counts = get_file_food_counts(\n",
    "            gnps_network, sample_types_simple, groups, [filename], level)\n",
    "        if len(file_food_counts) > 0:\n",
    "            food_counts.append(file_food_counts)\n",
    "            index.append((filename, timepoint))\n",
    "\n",
    "food_counts = (pd.concat(food_counts, axis=1, sort=True)\n",
    "               .fillna(0).astype(int).T)\n",
    "food_counts['filename'] = [filename for filename, timepoint in index]\n",
    "food_counts['day'] = [timepoint for filename, timepoint in index]\n",
    "food_counts = food_counts.set_index(['filename', 'day'])\n",
    "food_counts = food_counts[['caffeine', 'theophylline'] +\n",
    "                          [col for col in food_counts.columns\n",
    "                           if col not in ['caffeine', 'theophylline']]]\n",
    "food_counts.to_csv(f'onr_{sample}_timepoints_filename.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cooccurring_coffee = get_cooccurring_foods(\n",
    "    gnps_network, sample_types_simple, groups, ['coffee'], level)\n",
    "cooccurring_coffee.to_csv(f'onr_{sample}_cooccurring_coffee.csv',\n",
    "                          header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
