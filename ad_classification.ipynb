{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import average_precision_score, \\\n",
    "    balanced_accuracy_score, precision_recall_curve, roc_auc_score, roc_curve\n",
    "from sklearn.model_selection import GridSearchCV, learning_curve, \\\n",
    "    StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot styling.\n",
    "plt.style.use(['seaborn-white', 'seaborn-paper'])\n",
    "plt.rc('font', family='sans-serif')\n",
    "sns.set_palette('Set1')\n",
    "sns.set_context('paper', font_scale=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gnps_compound_occurrence(filename, index_col='LibraryID',\n",
    "                                  drop_col=['TotalFiles']):\n",
    "    return (pd.read_csv(filename, sep='\\t').drop(columns=drop_col)\n",
    "            .set_index(index_col))\n",
    "\n",
    "\n",
    "def read_sample_metadata(filename, index_col='filename'):\n",
    "    return pd.read_csv(filename, sep='\\t').set_index(index_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_counts = pd.read_csv(\n",
    "    '../data/27_33_AD Plasma - CSF - FoodOmics 3500 FDR 0.01 tol 0.01 2 mincluster/'\n",
    "    'ad_file_food_count.csv').set_index('filename')\n",
    "sample_metadata = read_sample_metadata(\n",
    "    '../data/27_33_AD Plasma - CSF - FoodOmics 3500 FDR 0.01 tol 0.01 2 mincluster/'\n",
    "    'AD_metadata_JMG.txt')\n",
    "\n",
    "sample_metadata = sample_metadata[\n",
    "    sample_metadata['Specimen_Type'] == 'Plasma']\n",
    "food_counts = food_counts.reindex(sample_metadata.index)\n",
    "sample_metadata = sample_metadata.reindex(food_counts.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = food_counts.div(food_counts.sum(axis=1), axis=0)\n",
    "clss = np.asarray(sample_metadata['AD'] == 'Yes', np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeatedly evaluate the model to estimate its performance.\n",
    "n_splits = 100\n",
    "test_size = 0.2\n",
    "accuracies_train = np.empty(n_splits, np.float32)\n",
    "accuracies_test = np.empty(n_splits, np.float32)\n",
    "average_precisions_train = np.empty(n_splits, np.float32)\n",
    "average_precisions_test = np.empty(n_splits, np.float32)\n",
    "roc_aucs_train = np.empty(n_splits, np.float32)\n",
    "roc_aucs_test = np.empty(n_splits, np.float32)\n",
    "interval = np.linspace(0, 1, 101, dtype=np.float32)\n",
    "tprs_train = np.empty((n_splits, 101), np.float32)\n",
    "tprs_test = np.empty((n_splits, 101), np.float32)\n",
    "precisions_train = np.empty((n_splits, 101), np.float32)\n",
    "precisions_test = np.empty((n_splits, 101), np.float32)\n",
    "n_components = np.empty(n_splits, np.float32)\n",
    "for i, (train_index, test_index) in enumerate(\n",
    "        StratifiedShuffleSplit(n_splits, test_size, random_state=42).split(\n",
    "            features.values, clss)):\n",
    "    features_train, features_test = (features.values[train_index],\n",
    "                                     features.values[test_index])\n",
    "    clss_train, clss_test = clss[train_index], clss[test_index]\n",
    "    \n",
    "    classifier = GridSearchCV(\n",
    "        PLSRegression(scale=False),\n",
    "        param_grid={'n_components': np.arange(2, 11, 1)},\n",
    "        scoring='roc_auc',\n",
    "        n_jobs=-1,\n",
    "        cv=StratifiedShuffleSplit(n_splits, test_size, random_state=42))\n",
    "    \n",
    "    classifier.fit(features_train, clss_train)\n",
    "    pred_train = np.clip(classifier.predict(features_train), 0, 1)\n",
    "    pred_test = np.clip(classifier.predict(features_test), 0, 1)\n",
    "    \n",
    "    # Compute evaluation metrics on the train and test data.\n",
    "    accuracies_train[i] = balanced_accuracy_score(\n",
    "            clss_train, np.asarray(pred_train > 0.5, np.int))\n",
    "    accuracies_test[i] = balanced_accuracy_score(\n",
    "            clss_test, np.asarray(pred_test > 0.5, np.int))\n",
    "    average_precisions_train[i] = average_precision_score(\n",
    "        clss_train, pred_train)\n",
    "    average_precisions_test[i] = average_precision_score(\n",
    "        clss_test, pred_test)\n",
    "    roc_aucs_train[i] = roc_auc_score(clss_train, pred_train)\n",
    "    roc_aucs_test[i] = roc_auc_score(clss_test, pred_test)\n",
    "    fpr_train, tpr_train, _ = roc_curve(clss_train, pred_train)\n",
    "    tprs_train[i] = np.interp(interval, fpr_train, tpr_train)\n",
    "    fpr_test, tpr_test, _ = roc_curve(clss_test, pred_test)\n",
    "    tprs_test[i] = np.interp(interval, fpr_test, tpr_test)\n",
    "    precision_train, recall_train, _ = precision_recall_curve(\n",
    "        clss_train, pred_train)\n",
    "    precisions_train[i] = np.interp(\n",
    "        interval, recall_train[::-1], precision_train[::-1])\n",
    "    precision_test, recall_test, _ = precision_recall_curve(\n",
    "        clss_test, pred_test)\n",
    "    precisions_test[i] = np.interp(\n",
    "        interval, recall_test[::-1], precision_test[::-1])\n",
    "    n_components[i] = classifier.best_estimator_.n_components\n",
    "\n",
    "stats = {'accuracy_train': np.mean(accuracies_train),\n",
    "         'accuracy_std_train': np.std(accuracies_train),\n",
    "         'average_precision_train': np.mean(average_precisions_train),\n",
    "         'average_precision_std_train': np.std(average_precisions_train),\n",
    "         'roc_auc_train': np.mean(roc_aucs_train),\n",
    "         'roc_auc_std_train': np.std(roc_aucs_train),\n",
    "         'tpr_mean_train': np.mean(tprs_train, axis=0),\n",
    "         'tpr_std_train': np.std(tprs_train, axis=0),\n",
    "         'precision_mean_train': np.mean(precisions_train, axis=0),\n",
    "         'precision_std_train': np.std(precisions_train, axis=0),\n",
    "        \n",
    "         'accuracy_test': np.mean(accuracies_test),\n",
    "         'accuracy_std_test': np.std(accuracies_test),\n",
    "         'average_precision_test': np.mean(average_precisions_test),\n",
    "         'average_precision_std_test': np.std(average_precisions_test),\n",
    "         'roc_auc_test': np.mean(roc_aucs_test),\n",
    "         'roc_auc_std_test': np.std(roc_aucs_test),\n",
    "         'tpr_mean_test': np.mean(tprs_test, axis=0),\n",
    "         'tpr_std_test': np.std(tprs_test, axis=0),\n",
    "         'precision_mean_test': np.mean(precisions_test, axis=0),\n",
    "         'precision_std_test': np.std(precisions_test, axis=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = int(scipy.stats.mode(n_components)[0])\n",
    "print(f'Optimal number of PLS-DA components (mode): {n_components}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax = axes[0]\n",
    "interval = np.linspace(0, 1, 101)\n",
    "tpr_train = stats['tpr_mean_train']\n",
    "tpr_train[0], tpr_train[-1] = 0, 1\n",
    "ax.plot(interval, tpr_train,\n",
    "        label=f'AUC (train) = {stats[\"roc_auc_train\"]:.3f} '\n",
    "              f'± {stats[\"roc_auc_std_train\"]:.3f}')\n",
    "ax.fill_between(interval, tpr_train - stats['tpr_std_train'],\n",
    "                tpr_train + stats['tpr_std_train'], alpha=0.2)\n",
    "tpr_test = stats['tpr_mean_test']\n",
    "tpr_test[0], tpr_test[-1] = 0, 1\n",
    "ax.plot(interval, tpr_test,\n",
    "        label=f'AUC (test) = {stats[\"roc_auc_test\"]:.3f} '\n",
    "              f'± {stats[\"roc_auc_std_test\"]:.3f}')\n",
    "ax.fill_between(interval, tpr_test - stats['tpr_std_test'],\n",
    "                tpr_test + stats['tpr_std_test'], alpha=0.2)\n",
    "        \n",
    "ax.plot([0, 1], [0, 1], c='black', ls='--')\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "        \n",
    "ax = axes[1]\n",
    "precision_train = stats['precision_mean_train']\n",
    "ax.plot(interval, precision_train,\n",
    "        label=f'Avg precision (train) = '\n",
    "              f'{stats[\"average_precision_train\"]:.3f} ± '\n",
    "              f'{stats[\"average_precision_std_train\"]:.3f}')\n",
    "ax.fill_between(interval, precision_train - stats['precision_std_train'],\n",
    "                precision_train + stats['precision_std_train'], alpha=0.2)\n",
    "precision_test = stats['precision_mean_test']\n",
    "ax.plot(interval, precision_test,\n",
    "        label=f'Avg precision (test) = '\n",
    "              f'{stats[\"average_precision_test\"]:.3f} ± '\n",
    "              f'{stats[\"average_precision_std_test\"]:.3f}')\n",
    "ax.fill_between(interval, precision_test - stats['precision_std_test'],\n",
    "                precision_test + stats['precision_std_test'], alpha=0.2)\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "ax.set_xlabel('Recall')\n",
    "ax.set_ylabel('Precision')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('ad_classification.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    PLSRegression(n_components, scale=False), features.values, clss,\n",
    "    train_sizes=np.linspace(0.2, 1.0, 10),\n",
    "    cv=StratifiedShuffleSplit(100, test_size=0.2, random_state=42),\n",
    "    scoring='roc_auc', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "ax.plot(train_sizes, train_scores_mean, 'o-', label='Training score')\n",
    "ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                train_scores_mean + train_scores_std, alpha=0.2)\n",
    "ax.plot(train_sizes, test_scores_mean, 'o-', label='Test score')\n",
    "ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                test_scores_mean + test_scores_std, alpha=0.2)\n",
    "\n",
    "ax.set_xlabel('Number of training examples')\n",
    "ax.set_ylabel('AUROC')\n",
    "\n",
    "ax.legend(loc='lower right', frameon=False)\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "plt.savefig('ad_learning_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
